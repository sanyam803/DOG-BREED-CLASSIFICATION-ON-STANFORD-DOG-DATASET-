{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "from keras.preprocessing import image\n",
    "from keras import applications\n",
    "from keras.models import Sequential\n",
    "import os,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\dog-breed-classifier\n"
     ]
    }
   ],
   "source": [
    "cd E:\\dog-breed-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_array(fname):\n",
    "    return np.load(open(fname,'rb'))\n",
    "def load_Cropped_data():\n",
    "    X_train=load_array('train_dataset.npy')\n",
    "    train_labels=load_array('train_labels.npy')\n",
    "    X_test=load_array('test_dataset.npy','rb')\n",
    "    test_labels=load_array('test_labels.npy')\n",
    "    return X_train,train_labels,X_test,test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target=load_array('train_labels.npy')\n",
    "valid_target=load_array('valid_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor=load_array('train_tensor.npy')\n",
    "valid_tensor=load_array('valid_tensor.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step3'></a>\n",
    "# Create a CNN to Classify Dog Breeds (from Scratch)\n",
    "Here we are setting Up an architecture to classify Dog Breeds.\n",
    "The main Intitution Behind this is VGG16 network.\n",
    "\n",
    "\n",
    "### Pre-process the Data\n",
    "\n",
    "We rescale the images by dividing every pixel in every image by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize_Input(X):\n",
    "    minimum=0\n",
    "    maximum=255\n",
    "    X-minimum/(maximum-minimum)\n",
    "    return X                \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensor=Normalize_Input(train_tensor)\n",
    "valid_tensor=Normalize_Input(valid_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# create and configure augmented image generator\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (10% of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (10% of total height)\n",
    "    horizontal_flip=True) # randomly flip images horizontally\n",
    "\n",
    "# fit augmented image generator on data\n",
    "datagen.fit(train_tensors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define my own architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 222, 222, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 111, 111, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 111, 111, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 109, 109, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 54, 54, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 52, 52, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 26, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 10, 10, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 133)               34181     \n",
      "=================================================================\n",
      "Total params: 428,785\n",
      "Trainable params: 427,787\n",
      "Non-trainable params: 998\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(224, 224, 3)))\n",
    "model.add(Conv2D(filters=16, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "We train our model in the code cell below.  Notice that I am using model checkpointing to save the model that attains the best validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "333/334 [============================>.] - ETA: 0s - loss: 4.5252 - acc: 0.0459Epoch 00000: val_loss improved from inf to 4.32222, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "334/334 [==============================] - 62s - loss: 4.5257 - acc: 0.0458 - val_loss: 4.3222 - val_acc: 0.0599\n",
      "Epoch 2/10\n",
      "333/334 [============================>.] - ETA: 0s - loss: 4.0783 - acc: 0.0859Epoch 00001: val_loss improved from 4.32222 to 4.01191, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "334/334 [==============================] - 58s - loss: 4.0772 - acc: 0.0862 - val_loss: 4.0119 - val_acc: 0.0886\n",
      "Epoch 3/10\n",
      "333/334 [============================>.] - ETA: 0s - loss: 3.7164 - acc: 0.1381Epoch 00002: val_loss improved from 4.01191 to 3.69128, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "334/334 [==============================] - 58s - loss: 3.7160 - acc: 0.1383 - val_loss: 3.6913 - val_acc: 0.1198\n",
      "Epoch 4/10\n",
      "333/334 [============================>.] - ETA: 0s - loss: 3.4101 - acc: 0.1830Epoch 00003: val_loss improved from 3.69128 to 3.40369, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "334/334 [==============================] - 58s - loss: 3.4092 - acc: 0.1834 - val_loss: 3.4037 - val_acc: 0.1677\n",
      "Epoch 5/10\n",
      "333/334 [============================>.] - ETA: 0s - loss: 3.1321 - acc: 0.2366Epoch 00004: val_loss improved from 3.40369 to 3.18252, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "334/334 [==============================] - 58s - loss: 3.1330 - acc: 0.2362 - val_loss: 3.1825 - val_acc: 0.2240\n",
      "Epoch 6/10\n",
      "333/334 [============================>.] - ETA: 0s - loss: 2.8884 - acc: 0.2854Epoch 00005: val_loss improved from 3.18252 to 3.09669, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "334/334 [==============================] - 59s - loss: 2.8870 - acc: 0.2856 - val_loss: 3.0967 - val_acc: 0.2299\n",
      "Epoch 7/10\n",
      "333/334 [============================>.] - ETA: 0s - loss: 2.6632 - acc: 0.3249Epoch 00006: val_loss improved from 3.09669 to 2.98263, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "334/334 [==============================] - 58s - loss: 2.6624 - acc: 0.3249 - val_loss: 2.9826 - val_acc: 0.2623\n",
      "Epoch 8/10\n",
      "333/334 [============================>.] - ETA: 0s - loss: 2.4723 - acc: 0.3634Epoch 00007: val_loss improved from 2.98263 to 2.71618, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "334/334 [==============================] - 57s - loss: 2.4734 - acc: 0.3635 - val_loss: 2.7162 - val_acc: 0.3341\n",
      "Epoch 9/10\n",
      "333/334 [============================>.] - ETA: 0s - loss: 2.2560 - acc: 0.4162Epoch 00008: val_loss improved from 2.71618 to 2.64979, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "334/334 [==============================] - 57s - loss: 2.2569 - acc: 0.4159 - val_loss: 2.6498 - val_acc: 0.3497\n",
      "Epoch 10/10\n",
      "333/334 [============================>.] - ETA: 0s - loss: 2.0666 - acc: 0.4572Epoch 00009: val_loss improved from 2.64979 to 2.44549, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "334/334 [==============================] - 57s - loss: 2.0662 - acc: 0.4572 - val_loss: 2.4455 - val_acc: 0.3605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f210a4da828>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 20\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.bestaugmented.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "### Using Image Augmentation\n",
    "model.fit_generator(datagen.flow(train_tensors, train_targets, batch_size=batch_size),\n",
    "                    validation_data=(valid_tensors, valid_targets), \n",
    "                    steps_per_epoch=train_tensors.shape[0] // batch_size,\n",
    "                    epochs=epochs, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model with the Best Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.bestaugmented.from_scratch.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "\n",
    "Let's try out our model on the test dataset of dog images. This will be our \"test accuracy\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 33.6124%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "dog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(dog_breed_predictions)==np.argmax(test_targets, axis=1))/len(dog_breed_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Training\n",
    "We can resume training to see if accuracy improves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.8754 - acc: 0.4977Epoch 00000: val_loss did not improve\n",
      "334/334 [==============================] - 59s - loss: 1.8750 - acc: 0.4978 - val_loss: 2.5731 - val_acc: 0.3760\n",
      "Epoch 2/5\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.7301 - acc: 0.5390Epoch 00001: val_loss improved from 2.44549 to 2.26365, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "334/334 [==============================] - 58s - loss: 1.7306 - acc: 0.5391 - val_loss: 2.2637 - val_acc: 0.4096\n",
      "Epoch 3/5\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.6041 - acc: 0.5707Epoch 00002: val_loss improved from 2.26365 to 2.20628, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "334/334 [==============================] - 58s - loss: 1.6036 - acc: 0.5707 - val_loss: 2.2063 - val_acc: 0.4240\n",
      "Epoch 4/5\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.4767 - acc: 0.5947Epoch 00003: val_loss improved from 2.20628 to 2.19275, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "334/334 [==============================] - 58s - loss: 1.4755 - acc: 0.5946 - val_loss: 2.1927 - val_acc: 0.4347\n",
      "Epoch 5/5\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.3490 - acc: 0.6351Epoch 00004: val_loss improved from 2.19275 to 2.14167, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "334/334 [==============================] - 58s - loss: 1.3494 - acc: 0.6349 - val_loss: 2.1417 - val_acc: 0.4455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f210a4c6630>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 20\n",
    "epochs = 5\n",
    "\n",
    "model.fit_generator(datagen.flow(train_tensors, train_targets, batch_size=batch_size),\n",
    "                    validation_data=(valid_tensors, valid_targets), \n",
    "                    steps_per_epoch=train_tensors.shape[0] // batch_size,\n",
    "                    epochs=epochs, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.2440 - acc: 0.6595Epoch 00000: val_loss improved from 2.14167 to 2.04245, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "334/334 [==============================] - 59s - loss: 1.2430 - acc: 0.6597 - val_loss: 2.0425 - val_acc: 0.4611\n",
      "Epoch 2/5\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.1418 - acc: 0.6886Epoch 00001: val_loss did not improve\n",
      "334/334 [==============================] - 58s - loss: 1.1431 - acc: 0.6880 - val_loss: 2.0567 - val_acc: 0.4359\n",
      "Epoch 3/5\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.0476 - acc: 0.7107Epoch 00002: val_loss did not improve\n",
      "334/334 [==============================] - 58s - loss: 1.0465 - acc: 0.7112 - val_loss: 2.0488 - val_acc: 0.4874\n",
      "Epoch 4/5\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.9808 - acc: 0.7309Epoch 00003: val_loss improved from 2.04245 to 1.94961, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "334/334 [==============================] - 57s - loss: 0.9818 - acc: 0.7304 - val_loss: 1.9496 - val_acc: 0.4778\n",
      "Epoch 5/5\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.9058 - acc: 0.7423Epoch 00004: val_loss did not improve\n",
      "334/334 [==============================] - 58s - loss: 0.9059 - acc: 0.7425 - val_loss: 2.0029 - val_acc: 0.4802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f210a4c6588>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 20\n",
    "epochs = 5\n",
    "\n",
    "model.fit_generator(datagen.flow(train_tensors, train_targets, batch_size=batch_size),\n",
    "                    validation_data=(valid_tensors, valid_targets), \n",
    "                    steps_per_epoch=train_tensors.shape[0] // batch_size,\n",
    "                    epochs=epochs, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "103/104 [============================>.] - ETA: 0s - loss: 0.6295 - acc: 0.8381Epoch 00000: val_loss improved from 1.94961 to 1.72946, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "104/104 [==============================] - 58s - loss: 0.6297 - acc: 0.8379 - val_loss: 1.7295 - val_acc: 0.5281\n",
      "Epoch 2/5\n",
      "103/104 [============================>.] - ETA: 0s - loss: 0.5351 - acc: 0.8741Epoch 00001: val_loss improved from 1.72946 to 1.72020, saving model to saved_models/weights.bestaugmented.from_scratch.hdf5\n",
      "104/104 [==============================] - 55s - loss: 0.5352 - acc: 0.8737 - val_loss: 1.7202 - val_acc: 0.5305\n",
      "Epoch 3/5\n",
      "103/104 [============================>.] - ETA: 0s - loss: 0.4984 - acc: 0.8865Epoch 00002: val_loss did not improve\n",
      "104/104 [==============================] - 55s - loss: 0.4993 - acc: 0.8860 - val_loss: 1.7535 - val_acc: 0.5257\n",
      "Epoch 4/5\n",
      "103/104 [============================>.] - ETA: 0s - loss: 0.4612 - acc: 0.8941Epoch 00003: val_loss did not improve\n",
      "104/104 [==============================] - 56s - loss: 0.4622 - acc: 0.8931 - val_loss: 1.7339 - val_acc: 0.5150\n",
      "Epoch 5/5\n",
      "103/104 [============================>.] - ETA: 0s - loss: 0.4281 - acc: 0.9046Epoch 00004: val_loss did not improve\n",
      "104/104 [==============================] - 54s - loss: 0.4275 - acc: 0.9047 - val_loss: 1.7621 - val_acc: 0.5174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f210a4c6550>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "model.fit_generator(datagen.flow(train_tensors, train_targets, batch_size=batch_size),\n",
    "                    validation_data=(valid_tensors, valid_targets), \n",
    "                    steps_per_epoch=train_tensors.shape[0] // batch_size,\n",
    "                    epochs=epochs, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model Again\n",
    "After we test the model again we see that we improved test accuracy up to 51%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 51.0766%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "dog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(dog_breed_predictions)==np.argmax(test_targets, axis=1))/len(dog_breed_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
